{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ee543e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from tensorflow) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from tensorflow) (78.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from tensorflow) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from tensorflow) (4.13.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\shashvat singh\\desktop\\vnv3\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas scikit-learn tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f976e832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e7cd232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de4f0c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sustainability_data = pd.read_csv('farmer_advisor_dataset.csv')\n",
    "market_price_data = pd.read_csv('market_researcher_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "512aa427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import joblib\n",
    "\n",
    "# Example feature lists; adjust to your dataset\n",
    "numeric_features1 = [\"Demand_Index\", \"Supply_Index\", \"Competitor_Price_per_ton\", \"Economic_Indicator\",\"Weather_Impact_Score\",\"Consumer_Trend_Index\"]\n",
    "categorical_features1 = ['Product', 'Seasonal_Factor']\n",
    "\n",
    "# Create pipelines for numeric and categorical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine transformers using ColumnTransformer\n",
    "preprocessor_market = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features1),\n",
    "        ('cat', categorical_transformer, categorical_features1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the preprocessor using the training data (X_train should only contain the features)\n",
    "# preprocessor.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b62a3355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import joblib\n",
    "\n",
    "# Example feature lists; adjust to your dataset\n",
    "numeric_features2 = [\"Soil_pH\", \"Soil_Moisture\", \"Temperature_C\", \"Rainfall_mm\",\"Fertilizer_Usage_kg\",\"Pesticide_Usage_kg\",\"Crop_Yield_ton\"]\n",
    "categorical_features2 = [\"Crop_Type\",]\n",
    "\n",
    "# Create pipelines for numeric and categorical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine transformers using ColumnTransformer\n",
    "preprocessor_sus = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features2),\n",
    "        ('cat', categorical_transformer, categorical_features2)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the preprocessor using the training data (X_train should only contain the features)\n",
    "# preprocessor.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5a63ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import pickle\n",
    "\n",
    "# Define the preprocessing function for the market data\n",
    "def create_market_preprocessor(market_data_path):\n",
    "    # Load the market data\n",
    "    market_df = market_price_data\n",
    "    \n",
    "    # Drop Market_ID column\n",
    "    if 'Market_ID' in market_df.columns:\n",
    "        market_df = market_df.drop('Market_ID', axis=1)\n",
    "        market_df = market_df.drop('Market_Price_per_ton', axis=1)\n",
    "    \n",
    "    # Identify categorical columns that need label encoding\n",
    "    market_categorical_cols = ['Product', 'Seasonal_Factor']\n",
    "    market_numeric_cols = [col for col in market_df.columns if col not in market_categorical_cols]\n",
    "    \n",
    "    # Create label encoders for categorical columns\n",
    "    market_label_encoders = {}\n",
    "    for col in market_categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(market_df[col].astype(str))\n",
    "        market_label_encoders[col] = le\n",
    "    \n",
    "    # Create standard scaler for numeric columns\n",
    "    market_scaler = StandardScaler()\n",
    "    market_scaler.fit(market_df[market_numeric_cols])\n",
    "    \n",
    "    # Combine into a dictionary to save\n",
    "    scaler_market = {\n",
    "        'label_encoders': market_label_encoders,\n",
    "        'standard_scaler': market_scaler,\n",
    "        'categorical_cols': market_categorical_cols,\n",
    "        'numeric_cols': market_numeric_cols\n",
    "    }\n",
    "    \n",
    "    # Save the preprocessor\n",
    "    with open('scaler_market.pkl', 'wb') as f:\n",
    "        pickle.dump(scaler_market, f)\n",
    "    \n",
    "    return scaler_market\n",
    "\n",
    "# Define the preprocessing function for the farm/sustainability data\n",
    "def create_sustainability_preprocessor(farm_data_path):\n",
    "    # Load the farm data\n",
    "    farm_df = sustainability_data\n",
    "    \n",
    "    # Drop Farm_ID column\n",
    "    if 'Farm_ID' in farm_df.columns:\n",
    "        farm_df = farm_df.drop('Farm_ID', axis=1)\n",
    "        farm_df = farm_df.drop('Sustainability_Score', axis=1)\n",
    "    \n",
    "    # Identify categorical columns that need label encoding\n",
    "    farm_categorical_cols = ['Crop_Type']\n",
    "    farm_numeric_cols = [col for col in farm_df.columns if col not in farm_categorical_cols]\n",
    "    \n",
    "    # Create label encoders for categorical columns\n",
    "    farm_label_encoders = {}\n",
    "    for col in farm_categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(farm_df[col].astype(str))\n",
    "        farm_label_encoders[col] = le\n",
    "    \n",
    "    # Create standard scaler for numeric columns\n",
    "    farm_scaler = StandardScaler()\n",
    "    farm_scaler.fit(farm_df[farm_numeric_cols])\n",
    "    \n",
    "    # Combine into a dictionary to save\n",
    "    scaler_sus = {\n",
    "        'label_encoders': farm_label_encoders,\n",
    "        'standard_scaler': farm_scaler,\n",
    "        'categorical_cols': farm_categorical_cols,\n",
    "        'numeric_cols': farm_numeric_cols\n",
    "    }\n",
    "    \n",
    "    # Save the preprocessor\n",
    "    with open('scaler_sus.pkl', 'wb') as f:\n",
    "        pickle.dump(scaler_sus, f)\n",
    "    \n",
    "    return scaler_sus\n",
    "\n",
    "# Function to preprocess new data using the saved preprocessors\n",
    "def preprocess_market_data(data, preprocessor):\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Apply label encoders for categorical columns\n",
    "    for col, encoder in preprocessor['label_encoders'].items():\n",
    "        if col in df.columns:\n",
    "            df[col] = encoder.transform(df[col].astype(str))\n",
    "    \n",
    "    # Apply standard scaler for numeric columns\n",
    "    if len(preprocessor['numeric_cols']) > 0:\n",
    "        df[preprocessor['numeric_cols']] = preprocessor['standard_scaler'].transform(df[preprocessor['numeric_cols']])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def preprocess_sustainability_data(data, preprocessor):\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Apply label encoders for categorical columns\n",
    "    for col, encoder in preprocessor['label_encoders'].items():\n",
    "        if col in df.columns:\n",
    "            df[col] = encoder.transform(df[col].astype(str))\n",
    "    \n",
    "    # Apply standard scaler for numeric columns\n",
    "    if len(preprocessor['numeric_cols']) > 0:\n",
    "        df[preprocessor['numeric_cols']] = preprocessor['standard_scaler'].transform(df[preprocessor['numeric_cols']])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11c61aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save preprocessors first\n",
    "scaler_market = create_market_preprocessor('market_researcher_dataset.csv')\n",
    "scaler_sus = create_sustainability_preprocessor('farmer_advisor_dataset.csv')\n",
    "\n",
    "# Load the preprocessors\n",
    "with open('scaler_market.pkl', 'rb') as f:\n",
    "    loaded_market_preprocessor = pickle.load(f)\n",
    "\n",
    "with open('scaler_sus.pkl', 'rb') as f:\n",
    "    loaded_sustainability_preprocessor = pickle.load(f)\n",
    "\n",
    "# Use the preprocessing functions defined earlier\n",
    "preprocessed_market_data = preprocess_market_data(market_price_data.copy(), loaded_market_preprocessor)\n",
    "preprocessed_farm_data = preprocess_sustainability_data(sustainability_data.copy(), loaded_sustainability_preprocessor)\n",
    "\n",
    "print(\"Data preprocessing completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58cdf8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing completed successfully!\n",
      "Sustainability data shape: (8000, 11)\n",
      "Market data shape: (8000, 13)\n"
     ]
    }
   ],
   "source": [
    "# Split sustainability data into features and target\n",
    "X_sustainability = sustainability_data.drop(columns=['Sustainability_Score'])\n",
    "y_sustainability = sustainability_data['Sustainability_Score']\n",
    "\n",
    "# Split market price data into features and target\n",
    "X_market = market_price_data.drop(columns=['Market_Price_per_ton'])\n",
    "y_market = market_price_data['Market_Price_per_ton']\n",
    "\n",
    "# Apply preprocessors to sustainability data\n",
    "X_sustainability_processed = preprocessor_sus.fit_transform(X_sustainability)\n",
    "y_sustainability_processed = y_sustainability  # No need to preprocess target variable\n",
    "\n",
    "# Apply preprocessors to market data\n",
    "X_market_processed = preprocessor_market.fit_transform(X_market)\n",
    "y_market_processed = y_market  # No need to preprocess target variable\n",
    "\n",
    "# Create training and test sets for sustainability data\n",
    "X_sus_train, X_sus_test, y_sus_train, y_sus_test = train_test_split(\n",
    "    X_sustainability_processed, y_sustainability_processed, \n",
    "    test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create training and test sets for market price data\n",
    "X_market_train, X_market_test, y_market_train, y_market_test = train_test_split(\n",
    "    X_market_processed, y_market_processed, \n",
    "    test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Convert sparse matrices to dense arrays for neural network if needed\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "X_sus_train = X_sus_train.toarray() if issparse(X_sus_train) else X_sus_train\n",
    "X_sus_test = X_sus_test.toarray() if issparse(X_sus_test) else X_sus_test\n",
    "X_market_train = X_market_train.toarray() if issparse(X_market_train) else X_market_train\n",
    "X_market_test = X_market_test.toarray() if issparse(X_market_test) else X_market_test\n",
    "\n",
    "# Save preprocessors\n",
    "import joblib\n",
    "joblib.dump(preprocessor_sus, 'preprocessor_sus.joblib')\n",
    "joblib.dump(preprocessor_market, 'preprocessor_market.joblib')\n",
    "\n",
    "with open('preprocessor_market.pkl', 'wb') as f:\n",
    "        pickle.dump(preprocessor_market, f)\n",
    "\n",
    "with open('preprocessor_sus.pkl', 'wb') as f:\n",
    "        pickle.dump(preprocessor_sus, f)\n",
    "\n",
    "print(\"Data preprocessing completed successfully!\")\n",
    "print(f\"Sustainability data shape: {X_sus_train.shape}\")\n",
    "print(f\"Market data shape: {X_market_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86caefce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create training and test sets for sustainability data\n",
    "X_sus_train, X_sus_test, y_sus_train, y_sus_test = train_test_split(\n",
    "    X_sustainability, y_sustainability, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create training and test sets for market price data\n",
    "X_market_train, X_market_test, y_market_train, y_market_test = train_test_split(\n",
    "    X_market, y_market, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26e2fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e442ee94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shashvat Singh\\Desktop\\vnv3\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 2773.7141 - mae: 44.5625 - val_loss: 848.9009 - val_mae: 24.9639\n",
      "Epoch 2/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 815.7899 - mae: 24.5127 - val_loss: 836.1210 - val_mae: 24.8085\n",
      "Epoch 3/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 827.7446 - mae: 24.6647 - val_loss: 835.0690 - val_mae: 24.8054\n",
      "Epoch 4/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 827.0107 - mae: 24.7263 - val_loss: 834.8760 - val_mae: 24.7721\n",
      "Epoch 5/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 816.8625 - mae: 24.5864 - val_loss: 835.0338 - val_mae: 24.7954\n",
      "Epoch 6/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 823.3554 - mae: 24.6857 - val_loss: 837.5551 - val_mae: 24.8190\n",
      "Epoch 7/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 817.2236 - mae: 24.6471 - val_loss: 833.8536 - val_mae: 24.7627\n",
      "Epoch 8/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 820.2021 - mae: 24.7230 - val_loss: 831.4180 - val_mae: 24.7527\n",
      "Epoch 9/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 806.1259 - mae: 24.4061 - val_loss: 842.0031 - val_mae: 24.8630\n",
      "Epoch 10/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 803.1254 - mae: 24.3642 - val_loss: 839.3212 - val_mae: 24.8401\n",
      "Epoch 11/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 805.2460 - mae: 24.3900 - val_loss: 843.2744 - val_mae: 24.9008\n",
      "Epoch 12/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 835.2189 - mae: 25.0377 - val_loss: 834.4023 - val_mae: 24.7780\n",
      "Epoch 13/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 806.4228 - mae: 24.4667 - val_loss: 836.5581 - val_mae: 24.8164\n",
      "Epoch 14/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 799.0311 - mae: 24.2307 - val_loss: 833.3702 - val_mae: 24.7716\n",
      "Epoch 15/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 812.5041 - mae: 24.6002 - val_loss: 835.6395 - val_mae: 24.7890\n",
      "Epoch 16/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 813.1627 - mae: 24.5937 - val_loss: 834.5468 - val_mae: 24.7778\n",
      "Epoch 17/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 795.1869 - mae: 24.1872 - val_loss: 837.4617 - val_mae: 24.8240\n",
      "Epoch 18/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 806.4775 - mae: 24.3997 - val_loss: 833.4054 - val_mae: 24.7658\n",
      "Epoch 19/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 801.3386 - mae: 24.2565 - val_loss: 831.0753 - val_mae: 24.7389\n",
      "Epoch 20/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 812.0334 - mae: 24.5304 - val_loss: 833.6138 - val_mae: 24.7824\n",
      "Epoch 21/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 797.5438 - mae: 24.2791 - val_loss: 835.7414 - val_mae: 24.7920\n",
      "Epoch 22/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 825.8239 - mae: 24.9371 - val_loss: 833.5854 - val_mae: 24.7768\n",
      "Epoch 23/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 816.0989 - mae: 24.6265 - val_loss: 834.6042 - val_mae: 24.7805\n",
      "Epoch 24/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 789.9459 - mae: 24.1287 - val_loss: 835.1127 - val_mae: 24.7931\n",
      "Epoch 25/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 819.4070 - mae: 24.6439 - val_loss: 836.6143 - val_mae: 24.8207\n",
      "Epoch 26/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 806.8842 - mae: 24.5189 - val_loss: 835.7929 - val_mae: 24.8016\n",
      "Epoch 27/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 784.8666 - mae: 24.1098 - val_loss: 836.7957 - val_mae: 24.8065\n",
      "Epoch 28/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 808.2020 - mae: 24.5628 - val_loss: 835.8067 - val_mae: 24.7972\n",
      "Epoch 29/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 795.1240 - mae: 24.2651 - val_loss: 835.7139 - val_mae: 24.8083\n",
      "Epoch 30/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 799.3223 - mae: 24.4122 - val_loss: 836.9476 - val_mae: 24.8120\n",
      "Epoch 31/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 809.7615 - mae: 24.5397 - val_loss: 837.9486 - val_mae: 24.8176\n",
      "Epoch 32/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 807.3284 - mae: 24.4716 - val_loss: 838.8801 - val_mae: 24.8304\n",
      "Epoch 33/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 800.8767 - mae: 24.3573 - val_loss: 834.2951 - val_mae: 24.7801\n",
      "Epoch 34/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 814.1120 - mae: 24.6217 - val_loss: 837.3912 - val_mae: 24.8041\n",
      "Epoch 35/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 792.5187 - mae: 24.2209 - val_loss: 838.2134 - val_mae: 24.8296\n",
      "Epoch 36/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 802.0177 - mae: 24.4025 - val_loss: 836.7358 - val_mae: 24.8017\n",
      "Epoch 37/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 791.5015 - mae: 24.2717 - val_loss: 839.9970 - val_mae: 24.8539\n",
      "Epoch 38/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 817.0598 - mae: 24.5581 - val_loss: 841.5507 - val_mae: 24.8764\n",
      "Epoch 39/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 812.5243 - mae: 24.6318 - val_loss: 844.7851 - val_mae: 24.9006\n",
      "Epoch 40/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 794.2633 - mae: 24.1816 - val_loss: 835.9533 - val_mae: 24.7886\n",
      "Epoch 41/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 802.9516 - mae: 24.3996 - val_loss: 843.2166 - val_mae: 24.8931\n",
      "Epoch 42/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 790.6714 - mae: 24.1585 - val_loss: 838.9955 - val_mae: 24.8223\n",
      "Epoch 43/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 799.2318 - mae: 24.3552 - val_loss: 838.2897 - val_mae: 24.8151\n",
      "Epoch 44/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 793.1664 - mae: 24.2013 - val_loss: 838.4741 - val_mae: 24.8288\n",
      "Epoch 45/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 804.2289 - mae: 24.4743 - val_loss: 844.7003 - val_mae: 24.9030\n",
      "Epoch 46/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 781.7327 - mae: 24.0564 - val_loss: 843.0386 - val_mae: 24.8858\n",
      "Epoch 47/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 789.2939 - mae: 24.1271 - val_loss: 843.4419 - val_mae: 24.8798\n",
      "Epoch 48/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 787.2584 - mae: 24.0787 - val_loss: 844.8469 - val_mae: 24.9125\n",
      "Epoch 49/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 780.7323 - mae: 23.9908 - val_loss: 848.6451 - val_mae: 24.9689\n",
      "Epoch 50/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 795.3267 - mae: 24.2647 - val_loss: 841.4439 - val_mae: 24.8714\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shashvat Singh\\Desktop\\vnv3\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 99230.5234 - mae: 292.7558 - val_loss: 62813.9648 - val_mae: 221.8765\n",
      "Epoch 2/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 41253.9531 - mae: 170.3229 - val_loss: 14111.3564 - val_mae: 101.7235\n",
      "Epoch 3/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 13898.7529 - mae: 102.6964 - val_loss: 13858.3965 - val_mae: 101.1555\n",
      "Epoch 4/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 13729.5225 - mae: 101.6849 - val_loss: 13821.8447 - val_mae: 101.0751\n",
      "Epoch 5/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 13563.4570 - mae: 100.7585 - val_loss: 13784.1816 - val_mae: 100.9642\n",
      "Epoch 6/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 13448.5283 - mae: 100.4918 - val_loss: 13786.2061 - val_mae: 100.9894\n",
      "Epoch 7/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 13409.1240 - mae: 100.0133 - val_loss: 13824.4033 - val_mae: 101.0538\n",
      "Epoch 8/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 13350.0635 - mae: 100.0014 - val_loss: 13791.6836 - val_mae: 101.1261\n",
      "Epoch 9/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 13282.9795 - mae: 99.7217 - val_loss: 13827.1250 - val_mae: 101.1020\n",
      "Epoch 10/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 13478.3535 - mae: 100.9254 - val_loss: 13792.3125 - val_mae: 101.0939\n",
      "Epoch 11/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 13502.7080 - mae: 100.6125 - val_loss: 13752.3760 - val_mae: 101.0153\n",
      "Epoch 12/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 13304.2393 - mae: 99.7987 - val_loss: 13750.4570 - val_mae: 100.9344\n",
      "Epoch 13/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13025.5273 - mae: 98.3377 - val_loss: 13749.8887 - val_mae: 100.9785\n",
      "Epoch 14/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 13127.2129 - mae: 99.1310 - val_loss: 13755.9014 - val_mae: 100.9492\n",
      "Epoch 15/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13483.7266 - mae: 100.7911 - val_loss: 13760.3174 - val_mae: 100.9852\n",
      "Epoch 16/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13164.4551 - mae: 99.3888 - val_loss: 13808.5146 - val_mae: 101.2077\n",
      "Epoch 17/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 13244.3398 - mae: 99.9203 - val_loss: 13733.5254 - val_mae: 100.9503\n",
      "Epoch 18/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 13281.7920 - mae: 100.1732 - val_loss: 13727.6201 - val_mae: 100.9828\n",
      "Epoch 19/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13149.2393 - mae: 99.4838 - val_loss: 13771.8262 - val_mae: 101.0724\n",
      "Epoch 20/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 13036.2285 - mae: 98.8270 - val_loss: 13740.8525 - val_mae: 101.0009\n",
      "Epoch 21/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 13133.3008 - mae: 99.1790 - val_loss: 13738.1211 - val_mae: 101.0542\n",
      "Epoch 22/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 13089.0537 - mae: 99.0989 - val_loss: 13755.0625 - val_mae: 101.0889\n",
      "Epoch 23/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 13624.9990 - mae: 101.5862 - val_loss: 13731.8408 - val_mae: 100.9846\n",
      "Epoch 24/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12972.6787 - mae: 98.4295 - val_loss: 13748.3984 - val_mae: 101.0325\n",
      "Epoch 25/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 13134.3604 - mae: 99.0883 - val_loss: 13734.5127 - val_mae: 100.9747\n",
      "Epoch 26/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 13228.5186 - mae: 100.0263 - val_loss: 13748.8320 - val_mae: 100.9874\n",
      "Epoch 27/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 13239.0566 - mae: 99.5983 - val_loss: 13765.9912 - val_mae: 101.0853\n",
      "Epoch 28/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 13467.1465 - mae: 100.8877 - val_loss: 13760.0889 - val_mae: 101.0732\n",
      "Epoch 29/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12834.8975 - mae: 97.7065 - val_loss: 13753.5361 - val_mae: 101.0804\n",
      "Epoch 30/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 12841.8760 - mae: 97.7109 - val_loss: 13780.1602 - val_mae: 101.1519\n",
      "Epoch 31/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 13181.0693 - mae: 99.7170 - val_loss: 13768.3311 - val_mae: 101.0821\n",
      "Epoch 32/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 13186.7500 - mae: 99.4619 - val_loss: 13731.3691 - val_mae: 100.9180\n",
      "Epoch 33/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 13051.2139 - mae: 98.7483 - val_loss: 13766.9424 - val_mae: 101.0987\n",
      "Epoch 34/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 13172.8047 - mae: 99.3084 - val_loss: 13756.1172 - val_mae: 101.0623\n",
      "Epoch 35/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 13008.7646 - mae: 98.9236 - val_loss: 13724.5723 - val_mae: 100.9818\n",
      "Epoch 36/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13156.8936 - mae: 99.4910 - val_loss: 13742.8574 - val_mae: 101.0069\n",
      "Epoch 37/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12984.5352 - mae: 98.9485 - val_loss: 13762.9277 - val_mae: 101.0710\n",
      "Epoch 38/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 13085.9375 - mae: 99.1562 - val_loss: 13726.4785 - val_mae: 100.9596\n",
      "Epoch 39/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 13129.7324 - mae: 99.3173 - val_loss: 13748.1348 - val_mae: 101.0587\n",
      "Epoch 40/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12949.7539 - mae: 98.5632 - val_loss: 13851.6133 - val_mae: 101.2855\n",
      "Epoch 41/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 13190.9268 - mae: 99.8095 - val_loss: 13725.8945 - val_mae: 100.9480\n",
      "Epoch 42/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 13052.9453 - mae: 99.0177 - val_loss: 13778.8525 - val_mae: 101.1690\n",
      "Epoch 43/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 13480.6943 - mae: 100.8705 - val_loss: 13771.3779 - val_mae: 101.1546\n",
      "Epoch 44/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 13103.7998 - mae: 99.2159 - val_loss: 13729.6279 - val_mae: 100.9476\n",
      "Epoch 45/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12974.8682 - mae: 98.5727 - val_loss: 13748.9717 - val_mae: 101.0641\n",
      "Epoch 46/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 12963.8574 - mae: 98.3938 - val_loss: 13783.4121 - val_mae: 101.1548\n",
      "Epoch 47/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 13135.0352 - mae: 99.4882 - val_loss: 13734.5498 - val_mae: 101.0155\n",
      "Epoch 48/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 12957.1562 - mae: 98.8893 - val_loss: 13785.1064 - val_mae: 101.1803\n",
      "Epoch 49/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 13200.1455 - mae: 99.8640 - val_loss: 13775.2188 - val_mae: 101.1343\n",
      "Epoch 50/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 13025.8506 - mae: 99.0793 - val_loss: 13743.0010 - val_mae: 101.0167\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 884.2354 - mae: 25.6873\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 13384.6465 - mae: 100.2007\n",
      "Sustainability Model Evaluation - Loss: 847.4532470703125, MAE: 25.083271026611328\n",
      "Market Price Model Evaluation - Loss: 13653.4677734375, MAE: 100.77552795410156\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    }
   ],
   "source": [
    "scaler_sus = StandardScaler()\n",
    "X_sus_train = scaler_sus.fit_transform(X_sus_train)\n",
    "X_sus_test = scaler_sus.transform(X_sus_test)\n",
    "\n",
    "scaler_market = StandardScaler()\n",
    "X_market_train = scaler_market.fit_transform(X_market_train)\n",
    "X_market_test = scaler_market.transform(X_market_test)\n",
    "\n",
    "# Define the ANN model for sustainability score prediction\n",
    "model_sustainability = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_sus_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "model_sustainability.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the sustainability model with the callback\n",
    "model_sustainability.fit(\n",
    "    X_sus_train, y_sus_train,\n",
    "    epochs=50, batch_size=32,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Define the ANN model for market price prediction\n",
    "model_market_price = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_market_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "model_market_price.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the market price model with the callback\n",
    "model_market_price.fit(\n",
    "    X_market_train, y_market_train,\n",
    "    epochs=50, batch_size=32,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Evaluate the models\n",
    "sustainability_eval = model_sustainability.evaluate(X_sus_test, y_sus_test)\n",
    "market_price_eval = model_market_price.evaluate(X_market_test, y_market_test)\n",
    "\n",
    "print(f\"Sustainability Model Evaluation - Loss: {sustainability_eval[0]}, MAE: {sustainability_eval[1]}\")\n",
    "print(f\"Market Price Model Evaluation - Loss: {market_price_eval[0]}, MAE: {market_price_eval[1]}\")\n",
    "\n",
    "# Make predictions\n",
    "sustainability_predictions = model_sustainability.predict(X_sus_test)\n",
    "market_price_predictions = model_market_price.predict(X_market_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1736ba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model_sustainability.save('model_sustainability.keras')\n",
    "model_market_price.save('model_market_price.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab0562a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved successfully in pickle format.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('model_sustainability.pkl', 'wb') as file:\n",
    "    pickle.dump(model_sustainability, file)\n",
    "                \n",
    "# Save the market price model\n",
    "with open('model_market_price.pkl', 'wb') as file:\n",
    "    pickle.dump(model_market_price, file)\n",
    "\n",
    "print(\"Models saved successfully in pickle format.\")\n",
    "           "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
